{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание к лекции \"Основы веб-скрапинга и работы с API\"\n",
    "### Задание 1\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>сегодня в 13:56</td>\n",
       "      <td>С каких книг можно начать изучать программиров...</td>\n",
       "      <td>https://habr.com/ru/post/536172/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>сегодня в 13:13</td>\n",
       "      <td>Как я научила свой компьютер играть в пары исп...</td>\n",
       "      <td>https://habr.com/ru/post/536162/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                                              title  \\\n",
       "0  сегодня в 13:56  С каких книг можно начать изучать программиров...   \n",
       "0  сегодня в 13:13  Как я научила свой компьютер играть в пары исп...   \n",
       "\n",
       "                               link  \n",
       "0  https://habr.com/ru/post/536172/  \n",
       "0  https://habr.com/ru/post/536162/  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYWORDS = ['python', 'парсинг']\n",
    "def get_results (words, URL_1 = 'https://habr.com/ru/all/'):\n",
    "    res = requests.get(URL_1)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    news_blocks = soup.find_all('article', class_ = 'post post_preview')\n",
    "    \n",
    "    preview = pd.DataFrame()\n",
    "    \n",
    "    for news_block in news_blocks:\n",
    "        for key in KEYWORDS:\n",
    "            if key.lower() in news_block.text.lower():\n",
    "                date = news_block.find('span', class_ = 'post__time').text\n",
    "                title = news_block.find('h2', class_ = 'post__title').text\n",
    "                link = news_block.find('a', class_ = 'post__title_link').get('href')\n",
    "                all_inf = {'date': date, 'title': title.strip(), 'link': link}\n",
    "                preview = pd.concat([preview, pd.DataFrame([all_inf])])\n",
    "          \n",
    "    preview = preview.drop_duplicates()\n",
    "    return preview\n",
    "get_results (KEYWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода:\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>\n",
    "\n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>description</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>Login credentials for over 32 Million Twitter ...</td>\n",
       "      <td>2016-10-26T00:00:00Z</td>\n",
       "      <td>metallurg_annet@mail.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eina.ru</td>\n",
       "      <td>In November 2020, a collection of over 23,000 ...</td>\n",
       "      <td>2020-12-10T00:00:00Z</td>\n",
       "      <td>metallurg_annet@mail.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>last.fm</td>\n",
       "      <td>In March 2012, the British music streaming ser...</td>\n",
       "      <td>2016-10-25T00:00:00Z</td>\n",
       "      <td>metallurg_annet@mail.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>metallurg_annet@mail.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>livejournal.com</td>\n",
       "      <td>In 2017, social network LiveJournal's database...</td>\n",
       "      <td>2019-05-23T00:00:00Z</td>\n",
       "      <td>metallurg_annet@mail.ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              site                                        description  \\\n",
       "0      twitter.com  Login credentials for over 32 Million Twitter ...   \n",
       "1          eina.ru  In November 2020, a collection of over 23,000 ...   \n",
       "2          last.fm  In March 2012, the British music streaming ser...   \n",
       "3        adobe.com  In October of 2013, criminals penetrated Adobe...   \n",
       "4  livejournal.com  In 2017, social network LiveJournal's database...   \n",
       "\n",
       "            publishDate                    email  \n",
       "0  2016-10-26T00:00:00Z  metallurg_annet@mail.ru  \n",
       "1  2020-12-10T00:00:00Z  metallurg_annet@mail.ru  \n",
       "2  2016-10-25T00:00:00Z  metallurg_annet@mail.ru  \n",
       "3  2016-10-21T00:00:00Z  metallurg_annet@mail.ru  \n",
       "4  2019-05-23T00:00:00Z  metallurg_annet@mail.ru  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMAIL = ['metallurg_annet@mail.ru']\n",
    "url = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "headers = {'Vaar-Header-App-Product': 'hackcheck-web-avast','Vaar-Version': '0'}\n",
    "addresses = {'emailAddresses': EMAIL}\n",
    "\n",
    "res = requests.post(url, json=addresses, headers=headers)\n",
    "\n",
    "df = pd.DataFrame(res.json()['breaches']).T.reset_index() \n",
    "\n",
    "df = df[['site', 'description', 'publishDate']]\n",
    "df['email'] = [', '.join(el.keys()) for el in list(res.json()['data'].values())]\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
